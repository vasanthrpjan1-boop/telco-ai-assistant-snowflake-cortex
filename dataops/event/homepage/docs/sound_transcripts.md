# <h1black>Analyse </h1black><h1blue>Sound Transcripts</h1blue>

So far, you have learnt about processing unstructured text data using **Document AI** and Cortex Parse document.  But what happens if the data comes from sound files?

In this section you will learn how to transform sound transcript data to view sentiment of earnings calls over time, and present the results back using Streamlit

Today you will be using transcripts which were previously processed in Snowflake using the **Whisper** python service.  If you would like to try Whisper out yourself, please see the following quickstart:

[Building an AI Agent for Healthcare Using Snowflake Cortex, Notebooks and ML Classification](https://quickstarts.snowflake.com/guide/ai_agent_health_payers_cc/index.html)

**Let's Begin analysing sound transcript data**
- Go back to the home page and click on **Projects > Notebooks**
- Click on the **ANALYSE_SOUND** notebook to run

