{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "oez2qsqmc5v5td4g4gdt",
   "authorId": "3234949799362",
   "authorName": "BECKY2",
   "authorEmail": "becky.oconnor@snowflake.com",
   "sessionId": "a667843c-9bad-43b2-a349-73170d7a318e",
   "lastEditTime": 1739371586708
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463050b4-bef4-4c6b-bedf-d1851064869b",
   "metadata": {
    "name": "heading_create_service",
    "collapsed": false,
    "resultHeight": 183
   },
   "source": "### Create a Service to transcript the earnings call\nthis service is leveraging a container with whisper running on it - leverages pytorch (a deap leaning framework) to parse and transcribe the text.  Follow the instructions here to set up the container which I used.\n\n- git hub https://github.com/michaelgorkow/scs_whisper, \n- blog post https://github.com/michaelgorkow/scs_whisper"
  },
  {
   "cell_type": "code",
   "id": "6e93ce76-16ac-4060-b673-2674cbd4b611",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "resultHeight": 111,
    "collapsed": false
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\nALTER COMPUTE POOL GPU_COMPUTE_FOR_SOUND_TO_TEXT_MED SUSPEND;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "create_service_2",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "USE ROLE CONTAINER_RUNTIME_LAB_USER;\n\nCREATE SERVICE if not exists SOUND.WHISPER_APP\n  IN COMPUTE POOL gpu_compute_for_sound_to_text_MED\n  FROM @SOUND.WHISPER_APP\n  SPEC='spec.yml'\n  MIN_INSTANCES=1\n  MAX_INSTANCES=3\n  EXTERNAL_ACCESS_INTEGRATIONS = (CONTAINER_ACCESS_INTEGRATION);\n\nALTER SERVICE SOUND.WHISPER_APP RESUME;\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6d580ebb-9897-4202-a791-1f761c9d3edc",
   "metadata": {
    "language": "sql",
    "name": "is_the_service_running",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CALL SYSTEM$GET_SERVICE_STATUS('SOUND.WHISPER_APP')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2f5b171-9fec-40bc-a3ae-12247a9c1c3c",
   "metadata": {
    "language": "sql",
    "name": "view_logs",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "USE SCHEMA SOUND;\nSELECT value AS log_line\nFROM TABLE(\n SPLIT_TO_TABLE(SYSTEM$GET_SERVICE_LOGS('WHISPER_APP', 0, 'whisper-service-container'), '\\n')\n  );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aecbdac5-49d8-43f2-8e19-be5323d1ce3d",
   "metadata": {
    "name": "heading_create_functions",
    "collapsed": false,
    "resultHeight": 47
   },
   "source": "#### Create 2 Functions"
  },
  {
   "cell_type": "markdown",
   "id": "6dfbdaba-7740-473b-b949-f34a026e4a99",
   "metadata": {
    "name": "heading_f1",
    "collapsed": false,
    "resultHeight": 31
   },
   "source": "##### Function 1 - Detect Language"
  },
  {
   "cell_type": "code",
   "id": "76c1bcbb-6c8e-4934-8fa6-1486be015b14",
   "metadata": {
    "language": "sql",
    "name": "function_to_detect_language",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FUNCTION UTILS.DETECT_LANGUAGE(AUDIO_FILE TEXT, ENCODE BOOLEAN)\nRETURNS VARIANT\nSERVICE=SOUND.WHISPER_APP\nENDPOINT=API\nAS '/detect-language';",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d64645c3-64e6-4620-9f3e-487cce6e841e",
   "metadata": {
    "name": "heading_f2",
    "collapsed": false,
    "resultHeight": 31
   },
   "source": "##### Function 2 - Transcribe Text"
  },
  {
   "cell_type": "code",
   "id": "74fcb49e-df9c-41e9-9b75-fe4f57b4652a",
   "metadata": {
    "language": "sql",
    "name": "function_to_transcribe_sound",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FUNCTION UTILS.TRANSCRIBE(TASK TEXT, LANGUAGE TEXT, AUDIO_FILE TEXT, ENCODE BOOLEAN)\nRETURNS VARIANT\nSERVICE=SOUND.WHISPER_APP\nENDPOINT=API\nAS '/asr';",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db43f053-4480-4ab8-b503-d8d15e23d9fa",
   "metadata": {
    "name": "run_functions",
    "collapsed": false,
    "resultHeight": 47
   },
   "source": "#### Run The Functions"
  },
  {
   "cell_type": "code",
   "id": "36eeffd1-5a10-46fd-be4c-83d1b2078656",
   "metadata": {
    "language": "python",
    "name": "view_each_call",
    "resultHeight": 161,
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\nfrom snowflake.snowpark.functions import *\nfrom snowflake.snowpark.types import *\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n\nfiles = session.sql('''SELECT RELATIVE_PATH, GET_PRESIGNED_URL('@DATA.SOUND',RELATIVE_PATH) URL FROM DIRECTORY (@SNOWFLAKE_BUY_OR_SELL.DATA.SOUND)''')\n\n\nselect_call = st.selectbox('Select Call:', files.select('RELATIVE_PATH'))\n\nURL = files.filter(col('RELATIVE_PATH') == select_call).select('URL').collect()[0][0]\nst.audio(URL, format=\"audio/mpeg\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c87cb74-d27b-4d05-aced-f31271194089",
   "metadata": {
    "name": "Detect_Language",
    "collapsed": false,
    "resultHeight": 46
   },
   "source": "### Detect the Language"
  },
  {
   "cell_type": "code",
   "id": "210e678f-3814-4b20-9e75-b74c51a13e2f",
   "metadata": {
    "language": "sql",
    "name": "detect_language",
    "resultHeight": 182,
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT RELATIVE_PATH, UTILS.DETECT_LANGUAGE(GET_PRESIGNED_URL('@DATA.SOUND',RELATIVE_PATH),True) FROM DIRECTORY (@SNOWFLAKE_BUY_OR_SELL.DATA.SOUND)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "160d5b19-ed63-4ead-9622-bc26a0967692",
   "metadata": {
    "name": "heading_table_transcript",
    "collapsed": false,
    "resultHeight": 47
   },
   "source": "#### Create a table which will contain the transcript"
  },
  {
   "cell_type": "code",
   "id": "aa54974b-086e-4d3b-a58d-70fa30081dc6",
   "metadata": {
    "language": "sql",
    "name": "table_transcript",
    "resultHeight": 182,
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE TABLE if NOT EXISTS DATA.EARNINGS_CALL_TRANSCRIPT AS \n\nSELECT RELATIVE_PATH, UTILS.TRANSCRIBE('transcribe','english',GET_PRESIGNED_URL('@DATA.SOUND',RELATIVE_PATH),True) TRANSCRIPT FROM DIRECTORY (@SNOWFLAKE_BUY_OR_SELL.DATA.SOUND);\n\n\nSELECT * FROM DATA.EARNINGS_CALL_TRANSCRIPT",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c082740-2faf-4885-aab9-bb9ed19f3bcf",
   "metadata": {
    "name": "heading_view_transcript",
    "collapsed": false,
    "resultHeight": 46
   },
   "source": "### Transform the transcript table"
  },
  {
   "cell_type": "code",
   "id": "7893c881-d45a-4388-9dda-bdfce79a65ed",
   "metadata": {
    "language": "sql",
    "name": "create_table_formatted_transcripts_with_sentiments",
    "collapsed": false,
    "resultHeight": 252
   },
   "outputs": [],
   "source": "CREATE TABLE IF NOT EXISTS DATA.TRANSCRIBED_TRANSCRIPTS AS\n\nSELECT RELATIVE_PATH, PARSE_JSON(TRANSCRIPT):language::TEXT LANGUAGE,\n\nVALUE:end::FLOAT TIME_SECONDS,  \nVALUE:text::TEXT TEXT \nFROM DATA.EARNINGS_CALL_TRANSCRIPT,\nLATERAL FLATTEN (PARSE_JSON(TRANSCRIPT):segments);\n\nSELECT * FROM DATA.TRANSCRIBED_TRANSCRIPTS LIMIT 5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "098216c2-20b6-4935-b0d3-815986f9e664",
   "metadata": {
    "name": "heading_add_sentiment",
    "collapsed": false,
    "resultHeight": 47
   },
   "source": "#### Add Sentiment scores to the calls"
  },
  {
   "cell_type": "code",
   "id": "65821c72-41ad-4d5a-ab8a-fb9f290f24ec",
   "metadata": {
    "language": "sql",
    "name": "with_sentiment",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "SELECT *, SNOWFLAKE.CORTEX.SENTIMENT(TEXT) FROM DATA.TRANSCRIBED_TRANSCRIPTS",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4337bffc-9f87-4c3d-8739-6676a4b12549",
   "metadata": {
    "name": "heading_Streamlit",
    "collapsed": false,
    "resultHeight": 47
   },
   "source": "#### Put all together in Streamlit"
  },
  {
   "cell_type": "code",
   "id": "ce6068f0-ea09-47f0-b4c9-438ace28179c",
   "metadata": {
    "language": "python",
    "name": "earnings_sentiment",
    "resultHeight": 977,
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\nfrom snowflake.snowpark.functions import *\nfrom snowflake.snowpark.types import *\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\ndef sentiment(text):\n    return call_function('snowflake.cortex.sentiment',text)\n\ntranscript_with_sentiment = session.table('DATA.TRANSCRIBED_TRANSCRIPTS').with_column('sentiment',sentiment(col('TEXT')))\n\nst.markdown('#### Calls with Sentiment')\n\n\nst.dataframe(transcript_with_sentiment)\ncol1,col2,col3 = st.columns(3)\n\nwith col1:\n\n    st.markdown('#### Q1')\n    q1 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n    st.line_chart(q1,\n              y='SENTIMENT',x='TIME_SECONDS',color = '#29B5E8')\n    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n\nwith col2:\n    q2 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n    st.markdown('#### Q2')\n    st.line_chart(q2,\n              y='SENTIMENT',x='TIME_SECONDS',color = '#29B5E8')\n    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n\nwith col3:\n    \n    st.markdown('#### Q3')\n    q3 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n    st.line_chart(q3,\n              y='SENTIMENT',x='TIME_SECONDS',color = '#FF9F36')\n    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4d30301-7651-48e9-b3b6-9d1f9b480323",
   "metadata": {
    "language": "python",
    "name": "sentiment_minutes",
    "collapsed": false,
    "resultHeight": 464
   },
   "outputs": [],
   "source": "grouped = transcript_with_sentiment.with_column('TIME',time_from_parts(15,0,'TIME_SECONDS')).\\\nwith_column('MINUTES',date_trunc('minute','TIME'))\ngrouped = grouped.with_column('MINUTES',minute('MINUTES'))\ndata_grouped_minutes = grouped.group_by('RELATIVE_PATH','MINUTES').agg(array_agg('TEXT').alias('TEXT'),avg('SENTIMENT').alias('SENTIMENT'))\n\nst.markdown('''Data Grouped to Minutes''')\ndata_grouped_minutes\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eeb79850-3258-44dc-8552-ae0c126dd812",
   "metadata": {
    "language": "python",
    "name": "grouped_minutes",
    "collapsed": false,
    "resultHeight": 790,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "st.markdown('#### Sentiment Analysis during the duration of the last 3 quarterly earnings calls')\ncol1,col2,col3 = st.columns(3)\n\nwith col1:\n\n    st.markdown('#### Q1')\n    q1 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n    st.line_chart(q1,\n              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n\nwith col2:\n    q2 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n    st.markdown('#### Q2')\n    st.line_chart(q2,\n              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n\nwith col3:\n    \n    st.markdown('#### Q3')\n    q3 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n    st.line_chart(q3,\n              y='SENTIMENT',x='MINUTES',color = '#FF9F36')\n    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n\nst.markdown(f'''**:bulb: Most positive minute of the year**: \\\n{data_grouped_minutes.sort(col('SENTIMENT').desc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')\n\nst.markdown(f'''**:warning: Most negative minute of the year**: \\\n{data_grouped_minutes.sort(col('SENTIMENT').asc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc46c13e-7e46-46a9-b4ea-1a8f83294f61",
   "metadata": {
    "language": "python",
    "name": "format_text",
    "resultHeight": 439,
    "collapsed": false
   },
   "outputs": [],
   "source": "grouped_text = data_grouped_minutes.with_column('TEXT',replace(replace(replace(cast('TEXT',StringType()),'\"',''),'[',''),']',''))\ngrouped_text",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7f000610-a836-4b17-aa9e-c192b48379dc",
   "metadata": {
    "name": "heading_save_data_in_table",
    "collapsed": false,
    "resultHeight": 47
   },
   "source": "#### Save data in a table"
  },
  {
   "cell_type": "code",
   "id": "20573f93-500d-48d8-b4bd-aa7bf3334dbf",
   "metadata": {
    "language": "python",
    "name": "create_table",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "grouped_text.write.mode(\"overwrite\").save_as_table(\"data.summary_text\")",
   "execution_count": null
  }
 ]
}