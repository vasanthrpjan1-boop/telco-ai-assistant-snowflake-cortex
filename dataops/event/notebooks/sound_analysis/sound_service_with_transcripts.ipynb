{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463050b4-bef4-4c6b-bedf-d1851064869b",
   "metadata": {
    "collapsed": false,
    "name": "heading_create_service",
    "resultHeight": 183
   },
   "source": [
    "# Create a Service to transcrbe the earnings call\n",
    "The whisper service has already transcribed sound files relating to the earnings calls.  It was hosted on a snowpark container and it processed each file with a medium sized GPU.  Whisper leverages pytorch (a deap leaning framework) to parse and transcribe the text.  If you want to set this up yourself, follow the instructions here to set up the container in Snowflake.\n",
    "\n",
    "- git hub https://github.com/michaelgorkow/scs_whisper, \n",
    "- blog post https://github.com/michaelgorkow/scs_whisper\n",
    "\n",
    "There is also a quick start which also leverages the Whisper Service using a **Container Runtime Notebook**\n",
    "\n",
    "- https://quickstarts.snowflake.com/guide/ai_agent_health_payers_cc/index.html?index=..%2F..index#0\n",
    "\n",
    "For today, we will use the transcripts which were processed in advance of this lab.  For reference, the results are shared to you via the **Internal Marketplace**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43f053-4480-4ab8-b503-d8d15e23d9fa",
   "metadata": {
    "collapsed": false,
    "name": "run_functions",
    "resultHeight": 47
   },
   "source": [
    "####  Listen to the calls that were transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eeffd1-5a10-46fd-be4c-83d1b2078656",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "view_each_call",
    "resultHeight": 161
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "files = session.sql('''SELECT RELATIVE_PATH, GET_PRESIGNED_URL('@DOCUMENT_AI.EARNINGS_CALLS',RELATIVE_PATH) URL FROM DIRECTORY (@DOCUMENT_AI.EARNINGS_CALLS)''')\n",
    "\n",
    "\n",
    "select_call = st.selectbox('Select Call:', files.select('RELATIVE_PATH'))\n",
    "\n",
    "URL = files.filter(col('RELATIVE_PATH') == select_call).select('URL').collect()[0][0]\n",
    "st.audio(URL, format=\"audio/mpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d5b19-ed63-4ead-9622-bc26a0967692",
   "metadata": {
    "collapsed": false,
    "name": "heading_table_transcript",
    "resultHeight": 47
   },
   "source": [
    "#### The sound files have already been transcribed using the whisper service.\n",
    "We will now create a table based on the raw results produced by the Whisper Service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54974b-086e-4d3b-a58d-70fa30081dc6",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "table_transcript",
    "resultHeight": 182
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DEFAULT_SCHEMA.EARNINGS_CALL_TRANSCRIPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c082740-2faf-4885-aab9-bb9ed19f3bcf",
   "metadata": {
    "collapsed": false,
    "name": "heading_view_transcript",
    "resultHeight": 46
   },
   "source": [
    "### Transform the transcript table\n",
    "We are creating a table which is flattening the json data that was generated by whisper.  This creates a row for every snippet of commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893c881-d45a-4388-9dda-bdfce79a65ed",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "create_table_formatted_transcripts_with_sentiments",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS AS\n",
    "\n",
    "SELECT RELATIVE_PATH, PARSE_JSON(TRANSCRIPT):language::TEXT LANGUAGE,\n",
    "\n",
    "VALUE:end::FLOAT TIME_SECONDS,  \n",
    "VALUE:text::TEXT TEXT \n",
    "FROM DEFAULT_SCHEMA.EARNINGS_CALL_TRANSCRIPT,\n",
    "LATERAL FLATTEN (PARSE_JSON(TRANSCRIPT):segments);\n",
    "\n",
    "SELECT * FROM DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098216c2-20b6-4935-b0d3-815986f9e664",
   "metadata": {
    "collapsed": false,
    "name": "heading_add_sentiment",
    "resultHeight": 47
   },
   "source": [
    "#### Add Sentiment scores to the calls\n",
    "Here, Cortex Sentiment is being used to generate a sentiment score for each text snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65821c72-41ad-4d5a-ab8a-fb9f290f24ec",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "with_sentiment",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "SELECT *, SNOWFLAKE.CORTEX.SENTIMENT(TEXT) FROM DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337bffc-9f87-4c3d-8739-6676a4b12549",
   "metadata": {
    "collapsed": false,
    "name": "heading_Streamlit",
    "resultHeight": 47
   },
   "source": [
    "#### Put all together in Streamlit\n",
    "Let's now have a look at the results using a visualistion in Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6068f0-ea09-47f0-b4c9-438ace28179c",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "earnings_sentiment",
    "resultHeight": 977
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "def sentiment(text):\n",
    "    return call_function('snowflake.cortex.sentiment',text)\n",
    "\n",
    "transcript_with_sentiment = session.table('DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS').with_column('sentiment',sentiment(col('TEXT')))\n",
    "\n",
    "st.markdown('#### Calls with Sentiment')\n",
    "\n",
    "\n",
    "st.dataframe(transcript_with_sentiment)\n",
    "col1,col2,col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "\n",
    "    st.markdown('#### Q1')\n",
    "    q1 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n",
    "    st.line_chart(q1,\n",
    "              y='SENTIMENT',x='TIME_SECONDS',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col2:\n",
    "    q2 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n",
    "    st.markdown('#### Q2')\n",
    "    st.line_chart(q2,\n",
    "              y='SENTIMENT',x='TIME_SECONDS',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col3:\n",
    "    \n",
    "    st.markdown('#### Q3')\n",
    "    q3 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n",
    "    st.line_chart(q3,\n",
    "              y='SENTIMENT',x='TIME_SECONDS',color = '#FF9F36')\n",
    "    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b3428-ea67-40ca-a1b0-9263ea9a5d02",
   "metadata": {
    "collapsed": false,
    "name": "hard_to_read"
   },
   "source": [
    "You will see that the line charts are very hard to read.  Also with such a small snippet of information, it is difficult to get a good sentiment score.  Unlike the chunking which you did with the Analyst reports, this time we are going to group snippets of data together for every 60 seconds and then create an average sentiment for every minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d30301-7651-48e9-b3b6-9d1f9b480323",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "sentiment_minutes",
    "resultHeight": 464
   },
   "outputs": [],
   "source": [
    "grouped = transcript_with_sentiment.with_column('TIME',time_from_parts(15,0,'TIME_SECONDS')).\\\n",
    "with_column('MINUTES',date_trunc('minute','TIME'))\n",
    "grouped = grouped.with_column('MINUTES',minute('MINUTES'))\n",
    "data_grouped_minutes = grouped.group_by('RELATIVE_PATH','MINUTES').agg(array_agg('TEXT').alias('TEXT'),avg('SENTIMENT').alias('SENTIMENT'))\n",
    "\n",
    "st.markdown('''#### Data Grouped to Minutes''')\n",
    "data_grouped_minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df2b58-e1be-4ffd-94ed-30642dd1d85d",
   "metadata": {
    "collapsed": false,
    "name": "smoother"
   },
   "source": [
    "Below is a much smoother output - and a lot easier to read.  We are also able to view these grouped snippets in the visualistion.  Here, we are featuring the Most populate minute of the year, followed by the most negative minute of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb79850-3258-44dc-8552-ae0c126dd812",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "grouped_minutes",
    "resultHeight": 790
   },
   "outputs": [],
   "source": [
    "st.markdown('#### Sentiment Analysis during the duration of the last 3 quarterly earnings calls')\n",
    "col1,col2,col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "\n",
    "    st.markdown('#### Q1')\n",
    "    q1 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n",
    "    st.line_chart(q1,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col2:\n",
    "    q2 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n",
    "    st.markdown('#### Q2')\n",
    "    st.line_chart(q2,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col3:\n",
    "    \n",
    "    st.markdown('#### Q3')\n",
    "    q3 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n",
    "    st.line_chart(q3,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#FF9F36')\n",
    "    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "st.markdown(f'''**:bulb: Most positive minute of the year**: \\\n",
    "{data_grouped_minutes.sort(col('SENTIMENT').desc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')\n",
    "\n",
    "st.markdown(f'''**:warning: Most negative minute of the year**: \\\n",
    "{data_grouped_minutes.sort(col('SENTIMENT').asc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3e259-c75e-41a0-9577-513a6a5af6a5",
   "metadata": {
    "collapsed": false,
    "name": "regexp"
   },
   "source": [
    "Now lets remove the arrays to visualise pure text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46c13e-7e46-46a9-b4ea-1a8f83294f61",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "format_text",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "grouped_text = data_grouped_minutes.with_column(\n",
    "    'TEXT',\n",
    "    regexp_replace(cast(col('TEXT'), StringType()), r'[\\[\\]\"]', '')\n",
    ")\n",
    "grouped_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f000610-a836-4b17-aa9e-c192b48379dc",
   "metadata": {
    "collapsed": false,
    "name": "heading_save_data_in_table",
    "resultHeight": 47
   },
   "source": [
    "#### Save data in a table\n",
    "Finally lets save the result in a table.  Once this is complete, move to **Step 6** - Create a Search Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20573f93-500d-48d8-b4bd-aa7bf3334dbf",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_table",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "grouped_text.write.mode(\"overwrite\").save_as_table(\"DEFAULT_SCHEMA.summary_text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "becky.oconnor@snowflake.com",
   "authorId": "3843495225666",
   "authorName": "USER",
   "lastEditTime": 1741392550939,
   "notebookId": "r64jawhgtdfcqehyduu3",
   "sessionId": "d1444d7e-8430-4bc6-9b26-dd91a94d39dc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
